# ğŸ’³ Fraud Detection MLOps Pipeline

An end-to-end fraud detection system built with production-grade MLOps practices. Includes automated pipelines, model version control, and deployment-ready architecture.

## ğŸ—ï¸ System Architecture


**Architecture Highlights:**
- **Modular Pipelines**: Each stage is separated for maintainability and easier testing.
- **MLflow Integration**: Centralized experiment tracking and model registry management.
- **Docker & Kubernetes**: Containerized deployment ensuring consistency across environments.
- **Flask REST API**: Lightweight and production-ready serving interface.
- **Automated Retraining**: Continuous model updates driven by performance metrics.

## ğŸ› ï¸ Technology Stack

- **Machine Learning**: scikit-learn, pandas, numpy  
- **MLOps Tools**: MLflow (experiment tracking), DVC (data versioning), BentoML (serving)  
- **Infrastructure**: Docker, Kubernetes, Flask  
- **Development Environment**: Python 3.10, Jupyter notebooks  

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10 or higher
- Docker (optional, for containerized deployment)

## ğŸ”„ MLOps Pipeline

1. Data Management: Track and version datasets with DVC, including automated preprocessing.
2. Model Development: Monitor experiments with MLflow, perform cross-validation, and optimize hyperparameters.
3. Validation & Testing: Run automated tests and evaluate model performance using key metrics.
4. Deployment: Containerize models with Docker and orchestrate using Kubernetes with CI/CD integration.
5. Monitoring: Detect data drift, track model performance, and trigger automated retraining.
6. Production Serving: Expose a REST API with health checks and load balancing for reliable serving.

### Setup
```bash
git clone <repository-url>
cd fraud-detection-mlops
pip install -r requirements.txt
```

### ğŸ¯ Serve Model
```bash
# One-command solution: retrain + serve
python retrain_and_serve.py
# Web interface at http://localhost:3000
```

### ğŸ“Š Run EDA Analysis
```bash
# Execute all EDA notebooks
./run_eda_simple.sh

# Or run individual notebooks
jupyter notebook notebooks/
```


## ğŸ“Š EDA Notebooks

**Design Choice:** Conducted thorough exploratory data analysis to serve as the foundation of the MLOps pipeline, bridging critical gaps in typical data science workflows.

### ğŸ“ˆ 01_exploration.ipynb
- **Objective**: Perform full data profiling and statistical examination
- **Key Findings**: Severe class imbalance (577:1), PCA feature patterns, correlation structure insights
- **Implementation**: Automated execution with detailed and comprehensive visualizations

### ğŸ¯ 02_baseline_model.ipynb
- **Objective**: Set baseline performance for fraud detection models
- **Models Used**: Logistic Regression, Random Forest with class balancing techniques
- **Evaluation Metrics**: AUC-ROC, Precision-Recall curves, feature importance analysis
- **Implementation**: Cross-validation with statistical significance testing

### ğŸ”¬ 03_experiments.ipynb
- **Objective**: Explore advanced modeling techniques to improve predictive performance
- **Methods**: SMOTE oversampling, XGBoost, LightGBM, hyperparameter tuning
- **Implementation**: Modular design for easy experimentation and model comparison

## ğŸ“ Project Structure

```
fraud-detection-mlops/
â”œâ”€â”€ ğŸ“Š data/                    # Data management
â”‚   â”œâ”€â”€ raw/                    # Raw transaction data
â”‚   â””â”€â”€ processed/              # Preprocessed features
â”œâ”€â”€ ğŸ““ notebooks/               # EDA and experimentation
â”‚   â”œâ”€â”€ 01_exploration.ipynb    # Data profiling & analysis
â”‚   â”œâ”€â”€ 02_baseline_model.ipynb # Baseline model development
â”‚   â””â”€â”€ 03_experiments.ipynb    # Advanced techniques
â”œâ”€â”€ ğŸ¤– models/                  # Trained models & artifacts
â”œâ”€â”€ ğŸ”§ src/                     # Source code
â”‚   â”œâ”€â”€ data/                   # Data processing scripts
â”‚   â””â”€â”€ models/                 # ML model code
â”œâ”€â”€ ğŸ”„ pipelines/               # MLOps pipelines
â”‚   â”œâ”€â”€ training_pipeline.py    # Automated training
â”‚   â”œâ”€â”€ deployment_pipeline.py  # Deployment automation
â”‚   â””â”€â”€ monitoring_pipeline.py  # Performance monitoring
â”œâ”€â”€ ğŸ³ infra/                   # Infrastructure as code
â”‚   â”œâ”€â”€ docker/                 # Container definitions
â”‚   â””â”€â”€ k8s/                    # Kubernetes manifests
â”œâ”€â”€ ğŸ§ª tests/                   # Test suites
â”œâ”€â”€ ğŸ“ˆ mlruns/                  # MLflow experiment logs
â”œâ”€â”€ ğŸ”„ mlartifacts/             # MLflow model artifacts
â””â”€â”€ ğŸ“‹ requirements.txt         # Python dependencies

## ğŸ¯ Key Features

- **ğŸ”„ Continuous Training**: Automatically retrains models as new data becomes available  
- **ğŸ“Š Experiment Tracking**: Maintains full lineage from raw data through predictions  
- **ğŸ” Data Validation**: Performs automated quality checks and drift detection  
- **ğŸš€ One-Click Deployment**: Production-ready deployment via Docker and Kubernetes  
- **ğŸ“ˆ Performance Monitoring**: Tracks model health in real time  
- **ğŸ”’ Production Ready**: Secure, scalable, and robust architecture
